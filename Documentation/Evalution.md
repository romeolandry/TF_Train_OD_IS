# helpful

[Verifying mAP of TensorRT Optimized SSD and YOLOv3 Models](https://jkjung-avt.github.io/trt-detection-map/)
[mAP (mean Average Precision) for Object Detection](https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173)
https://blog.zenggyu.com/en/post/2018-12-16/an-introduction-to-evaluation-metrics-for-object-detection/
[Mask](https://www.programcreek.com/python/example/88588/pycocotools.cocoeval.COCOeval)
[COCO](https://cocodataset.org/#detection-eval)
https://python.hotexamples.com/examples/pycocotools.cocoeval/COCOeval/-/python-cocoeval-class-examples.html

[TF-TRT Best practice East as an Example](https://on-demand.gputechconf.com/gtc-cn/2019/pdf/CN9456/presentation.pdf)

[TensorRT and the Jetson Nano](https://rahulrav.com/blog/tensorrt_nano.html)

## Evaluate model 
[ jkjung-avt /tensorrt_demos ](https://github.com/jkjung-avt/tensorrt_demos)

## Convert

- Tensorflow Object detection API2 used with tensorflow 2.x doesn't freeze model. [Exporting a trained model for inference (Tensorflow 2) #9617](https://github.com/tensorflow/models/issues/9617)

- [onnx](https://github.com/onnx/tensorflow-onnx)

## Inference mask
   [inference with mask](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb?hl=ar#scrollTo=zl3qdtR1OvM_)

## Freeze Model from Checkpoint 
   [freeze Model](https://www.youtube.com/watch?v=OKieIB-QD4c)

   [tf2.x freeze model](https://leimao.github.io/blog/Save-Load-Inference-From-TF2-Frozen-Graph/)

## bbox and mask
[OD and bounding boxes](https://d2l.ai/chapter_computer-vision/bounding-box.html)

## Jetson Nano 

[Tensorflow on JN](https://www.youtube.com/watch?v=0X-uoIx_a9M)

## load saved model to compar
[import_pb_to_tensorboard](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/import_pb_to_tensorboard.py)

## opencv

https://gilberttanner.com/blog/run-tensorflow-on-the-jetson-nano

## TLT
https://developer.nvidia.com/transfer-learning-toolkit

## TRITON

https://developer.nvidia.com/blog/deploying-models-from-tensorflow-model-zoo-using-deepstream-and-triton-inference-server/
